# import plagiarism

# text = """ETL is a critical process for data integration and analytics. Some common use cases include: - Data warehousing: ETL pipelines are used to extract data from source systems such as databases, files and APIs, transform the data into a consistent format and then load it into a data warehouse. - Business intelligence: ETL is used to populate data marts and data warehouses used by BI tools. - Data migration: ETL is often used during data migrations when an organization needs to transition from one system to another. - Data integration: ETL makes possible the seamless integration of data from different sources. - Data cleansing and enrichment: ETL pipelines are also used to clean and standardize data. They also enrich data by incorporating missing information. - Batch processing: ETL jobs often run at scheduled intervals and process large amounts of data, ensuring that the data warehouse remains updated. - Data governance and compliance: ETL is a critical tool for the enforcement of data governance policies. Data can be encrypted during the transformation process to comply with data laws. - Real-time ETL: While traditional ETL is mostly done on schedule intervals (batches), real-time ETL is now used for scenarios that require instant updates, such as stock market updates. - Cloud data pipelines: ETL tools are used in cloud environments to facilitate the movement of data between cloud platforms and on-premises storage."""

# result = plagiarism.main(text)

# print(result)


import radarChart as r

r.main(1,2,3,4,6,5)

print(r)
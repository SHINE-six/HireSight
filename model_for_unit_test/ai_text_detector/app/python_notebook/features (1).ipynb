{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import textstat\n",
    "from language_tool_python import LanguageTool\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DATA_SET/final_test_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic NLP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['char_count'] = df['cleaned_text'].apply(len)\n",
    "\n",
    "df['word_count'] = df['cleaned_text'].apply(lambda x: len(word_tokenize(x))) # word count\n",
    "\n",
    "df['word_density'] = df['word_count'] / df['char_count'] # word density\n",
    "\n",
    "# punctuation count\n",
    "def punctuation_count(text):\n",
    "    return sum(1 for char in text if char in string.punctuation)\n",
    "\n",
    "df['punctuation_count'] = df['text'].apply(punctuation_count)\n",
    "\n",
    "# Upper case count\n",
    "def upper_case_count(text):\n",
    "    return sum(1 for char in text if char.isupper())\n",
    "\n",
    "df['upper_case_count'] = df['text'].apply(upper_case_count)\n",
    "\n",
    "def title_word_count(text):\n",
    "    return sum(1 for word in text.split() if word.istitle())\n",
    "\n",
    "df['title_word_count'] = df['text'].apply(title_word_count)\n",
    "\n",
    "# parts of speech\n",
    "def parts_of_speech(text):\n",
    "    pos_tags = pos_tag(word_tokenize(text))\n",
    "    \n",
    "    noun_count = sum(1 for tag in pos_tags if tag[1] in ['NN', 'NNS', 'NNP', 'NNPS'])\n",
    "    adv_count = sum(1 for tag in pos_tags if tag[1] in ['RB', 'RBR', 'RBS'])\n",
    "    verb_count = sum(1 for tag in pos_tags if tag[1] in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'])\n",
    "    adj_count = sum(1 for tag in pos_tags if tag[1] in ['JJ', 'JJR', 'JJS'])\n",
    "    pro_count = sum(1 for tag in pos_tags if tag[1] in ['PRP', 'PRP$', 'WP', 'WP$'])\n",
    "    return pd.Series([noun_count, adv_count, verb_count, adj_count, pro_count], index=['noun_count','adv_count','verb_count','adj_count','pro_count'])\n",
    "\n",
    "df[['noun_count','adv_count','verb_count','adj_count','pro_count']] = df['cleaned_text'].apply(lambda x: parts_of_speech(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [text.split() for text in df['cleaned_text']]\n",
    "\n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "\n",
    "corpus_bow = [dictionary.doc2bow(text) for text in corpus]\n",
    "\n",
    "# Training\n",
    "num_topics = 20\n",
    "lda_model = LdaModel(corpus_bow, num_topics=num_topics, id2word=dictionary, passes=15)\n",
    "\n",
    "topic_distribution = lda_model.get_document_topics(corpus_bow)\n",
    "\n",
    "for topic in range(num_topics):\n",
    "    df[f'topic_{topic + 1}_score'] = [next((t[1] for t in topic_dist if t[0] == topic), 0) for topic_dist in topic_distribution]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>upper_case_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_11_score</th>\n",
       "      <th>topic_12_score</th>\n",
       "      <th>topic_13_score</th>\n",
       "      <th>topic_14_score</th>\n",
       "      <th>topic_15_score</th>\n",
       "      <th>topic_16_score</th>\n",
       "      <th>topic_17_score</th>\n",
       "      <th>topic_18_score</th>\n",
       "      <th>topic_19_score</th>\n",
       "      <th>topic_20_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, cleaned_text, char_count, word_count, word_density, punctuation_count, upper_case_count, title_word_count, noun_count, adv_count, verb_count, adj_count, pro_count, topic_1_score, topic_2_score, topic_3_score, topic_4_score, topic_5_score, topic_6_score, topic_7_score, topic_8_score, topic_9_score, topic_10_score, topic_11_score, topic_12_score, topic_13_score, topic_14_score, topic_15_score, topic_16_score, topic_17_score, topic_18_score, topic_19_score, topic_20_score]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 33 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readability Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['flesch_kincaid_score'] = df['cleaned_text'].apply(lambda x: textstat.flesch_kincaid_grade(x))\n",
    "\n",
    "df['flesch_score'] = df['cleaned_text'].apply(lambda x: textstat.flesch_reading_ease(x))\n",
    "\n",
    "df['gunning_fog_score'] = df['cleaned_text'].apply(lambda x: textstat.gunning_fog(x))\n",
    "\n",
    "df['coleman_liau_score'] = df['cleaned_text'].apply(lambda x: textstat.coleman_liau_index(x))\n",
    "\n",
    "df['dale_chall_score'] = df['cleaned_text'].apply(lambda x: textstat.dale_chall_readability_score(x))\n",
    "\n",
    "df['ari_score'] = df['cleaned_text'].apply(lambda x: textstat.automated_readability_index(x))\n",
    "\n",
    "df['linsear_write_score'] = df['cleaned_text'].apply(lambda x: textstat.linsear_write_formula(x))\n",
    "\n",
    "df['spache_score'] = df['cleaned_text'].apply(lambda x: textstat.spache_readability(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>upper_case_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_19_score</th>\n",
       "      <th>topic_20_score</th>\n",
       "      <th>flesch_kincaid_score</th>\n",
       "      <th>flesch_score</th>\n",
       "      <th>gunning_fog_score</th>\n",
       "      <th>coleman_liau_score</th>\n",
       "      <th>dale_chall_score</th>\n",
       "      <th>ari_score</th>\n",
       "      <th>linsear_write_score</th>\n",
       "      <th>spache_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, cleaned_text, char_count, word_count, word_density, punctuation_count, upper_case_count, title_word_count, noun_count, adv_count, verb_count, adj_count, pro_count, topic_1_score, topic_2_score, topic_3_score, topic_4_score, topic_5_score, topic_6_score, topic_7_score, topic_8_score, topic_9_score, topic_10_score, topic_11_score, topic_12_score, topic_13_score, topic_14_score, topic_15_score, topic_16_score, topic_17_score, topic_18_score, topic_19_score, topic_20_score, flesch_kincaid_score, flesch_score, gunning_fog_score, coleman_liau_score, dale_chall_score, ari_score, linsear_write_score, spache_score]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 41 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_count(text):\n",
    "    words = word_tokenize(text)\n",
    "    pos_tags = pos_tag(words)\n",
    "    ner_tags = ne_chunk(pos_tags)\n",
    "    ner_count = sum(1 for chunk in ner_tags if hasattr(chunk, 'label'))\n",
    "    return ner_count\n",
    "\n",
    "df['ner_count'] = df['text'].apply(ner_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python\n",
    "correcter = language_tool_python.LanguageTool('en-US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\User\\\\OneDrive\\\\desktop\\\\HireMeModel\\\\feature_Named_Entity.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text error length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = LanguageTool('en-US')\n",
    "\n",
    "def error_length(text):\n",
    "    matches = tool.check(text)\n",
    "    return len(matches)\n",
    "\n",
    "df['error_length'] = df['text'].apply(error_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>source</th>\n",
       "      <th>RDizzl3_seven</th>\n",
       "      <th>model</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>...</th>\n",
       "      <th>flesch_kincaid_score</th>\n",
       "      <th>flesch_score</th>\n",
       "      <th>gunning_fog_score</th>\n",
       "      <th>coleman_liau_score</th>\n",
       "      <th>dale_chall_score</th>\n",
       "      <th>ari_score</th>\n",
       "      <th>linsear_write_score</th>\n",
       "      <th>spache_score</th>\n",
       "      <th>ner_count</th>\n",
       "      <th>error_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phones Modern humans today are always on their...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "      <td>human</td>\n",
       "      <td>phones modern humans today are always on their...</td>\n",
       "      <td>1972</td>\n",
       "      <td>378</td>\n",
       "      <td>0.191684</td>\n",
       "      <td>...</td>\n",
       "      <td>147.2</td>\n",
       "      <td>-286.82</td>\n",
       "      <td>151.94</td>\n",
       "      <td>8.68</td>\n",
       "      <td>24.77</td>\n",
       "      <td>187.4</td>\n",
       "      <td>53.0</td>\n",
       "      <td>54.82</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This essay will explain if drivers should or s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "      <td>human</td>\n",
       "      <td>this essay will explain if drivers should or s...</td>\n",
       "      <td>2018</td>\n",
       "      <td>366</td>\n",
       "      <td>0.181368</td>\n",
       "      <td>...</td>\n",
       "      <td>143.7</td>\n",
       "      <td>-283.10</td>\n",
       "      <td>148.70</td>\n",
       "      <td>10.42</td>\n",
       "      <td>24.34</td>\n",
       "      <td>182.9</td>\n",
       "      <td>57.0</td>\n",
       "      <td>53.46</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Driving while the use of cellular devices Toda...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "      <td>human</td>\n",
       "      <td>driving while the use of cellular devices toda...</td>\n",
       "      <td>1024</td>\n",
       "      <td>178</td>\n",
       "      <td>0.173828</td>\n",
       "      <td>...</td>\n",
       "      <td>71.5</td>\n",
       "      <td>-100.74</td>\n",
       "      <td>73.45</td>\n",
       "      <td>11.51</td>\n",
       "      <td>15.39</td>\n",
       "      <td>90.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>27.14</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phones &amp; Driving Drivers should not be able to...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "      <td>human</td>\n",
       "      <td>phones driving drivers should not be able to u...</td>\n",
       "      <td>1183</td>\n",
       "      <td>207</td>\n",
       "      <td>0.174979</td>\n",
       "      <td>...</td>\n",
       "      <td>82.8</td>\n",
       "      <td>-130.18</td>\n",
       "      <td>85.70</td>\n",
       "      <td>11.58</td>\n",
       "      <td>16.57</td>\n",
       "      <td>104.3</td>\n",
       "      <td>64.0</td>\n",
       "      <td>31.06</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cell Phone Operation While Driving The ability...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "      <td>human</td>\n",
       "      <td>cell phone operation while driving the ability...</td>\n",
       "      <td>1872</td>\n",
       "      <td>332</td>\n",
       "      <td>0.177350</td>\n",
       "      <td>...</td>\n",
       "      <td>131.6</td>\n",
       "      <td>-257.05</td>\n",
       "      <td>136.66</td>\n",
       "      <td>11.11</td>\n",
       "      <td>23.72</td>\n",
       "      <td>166.4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>49.31</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73567</th>\n",
       "      <td>im in middle school and I think that the princ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Grades for extracurricular activities</td>\n",
       "      <td>persuade_finetuned_llamas</td>\n",
       "      <td>False</td>\n",
       "      <td>llama</td>\n",
       "      <td>im in middle school and i think that the princ...</td>\n",
       "      <td>411</td>\n",
       "      <td>73</td>\n",
       "      <td>0.177616</td>\n",
       "      <td>...</td>\n",
       "      <td>29.4</td>\n",
       "      <td>14.30</td>\n",
       "      <td>31.39</td>\n",
       "      <td>10.82</td>\n",
       "      <td>12.88</td>\n",
       "      <td>36.9</td>\n",
       "      <td>40.5</td>\n",
       "      <td>13.02</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73568</th>\n",
       "      <td>I am writing you today to disagree with your t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Grades for extracurricular activities</td>\n",
       "      <td>persuade_finetuned_llamas</td>\n",
       "      <td>False</td>\n",
       "      <td>llama</td>\n",
       "      <td>i am writing you today to disagree with your t...</td>\n",
       "      <td>1634</td>\n",
       "      <td>213</td>\n",
       "      <td>0.130355</td>\n",
       "      <td>...</td>\n",
       "      <td>89.9</td>\n",
       "      <td>-170.11</td>\n",
       "      <td>95.15</td>\n",
       "      <td>22.94</td>\n",
       "      <td>24.58</td>\n",
       "      <td>116.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>34.79</td>\n",
       "      <td>9</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73569</th>\n",
       "      <td>Dear Principal , In conclusion , I would obser...</td>\n",
       "      <td>1</td>\n",
       "      <td>Grades for extracurricular activities</td>\n",
       "      <td>persuade_finetuned_llamas</td>\n",
       "      <td>False</td>\n",
       "      <td>llama</td>\n",
       "      <td>dear principal in conclusion i would observe t...</td>\n",
       "      <td>2569</td>\n",
       "      <td>381</td>\n",
       "      <td>0.148307</td>\n",
       "      <td>...</td>\n",
       "      <td>153.1</td>\n",
       "      <td>-323.71</td>\n",
       "      <td>157.96</td>\n",
       "      <td>17.55</td>\n",
       "      <td>31.78</td>\n",
       "      <td>196.2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>57.79</td>\n",
       "      <td>14</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73570</th>\n",
       "      <td>Dear Mrs . Principal , in these kinds of consi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Grades for extracurricular activities</td>\n",
       "      <td>persuade_finetuned_llamas</td>\n",
       "      <td>False</td>\n",
       "      <td>llama</td>\n",
       "      <td>dear mrs principal in these kinds of considera...</td>\n",
       "      <td>2357</td>\n",
       "      <td>346</td>\n",
       "      <td>0.146797</td>\n",
       "      <td>...</td>\n",
       "      <td>139.4</td>\n",
       "      <td>-288.18</td>\n",
       "      <td>144.64</td>\n",
       "      <td>17.96</td>\n",
       "      <td>29.93</td>\n",
       "      <td>179.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>52.78</td>\n",
       "      <td>21</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73571</th>\n",
       "      <td>I enjoyed Form five and excitedly ex claims ed...</td>\n",
       "      <td>1</td>\n",
       "      <td>Grades for extracurricular activities</td>\n",
       "      <td>persuade_finetuned_llamas</td>\n",
       "      <td>False</td>\n",
       "      <td>llama</td>\n",
       "      <td>i enjoyed form five and excitedly ex claims ed...</td>\n",
       "      <td>843</td>\n",
       "      <td>134</td>\n",
       "      <td>0.158956</td>\n",
       "      <td>...</td>\n",
       "      <td>55.6</td>\n",
       "      <td>-64.54</td>\n",
       "      <td>58.08</td>\n",
       "      <td>14.64</td>\n",
       "      <td>17.47</td>\n",
       "      <td>70.5</td>\n",
       "      <td>62.0</td>\n",
       "      <td>21.98</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73572 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      Phones Modern humans today are always on their...      0   \n",
       "1      This essay will explain if drivers should or s...      0   \n",
       "2      Driving while the use of cellular devices Toda...      0   \n",
       "3      Phones & Driving Drivers should not be able to...      0   \n",
       "4      Cell Phone Operation While Driving The ability...      0   \n",
       "...                                                  ...    ...   \n",
       "73567  im in middle school and I think that the princ...      1   \n",
       "73568  I am writing you today to disagree with your t...      1   \n",
       "73569  Dear Principal , In conclusion , I would obser...      1   \n",
       "73570  Dear Mrs . Principal , in these kinds of consi...      1   \n",
       "73571  I enjoyed Form five and excitedly ex claims ed...      1   \n",
       "\n",
       "                                 prompt_name                     source  \\\n",
       "0                         Phones and driving            persuade_corpus   \n",
       "1                         Phones and driving            persuade_corpus   \n",
       "2                         Phones and driving            persuade_corpus   \n",
       "3                         Phones and driving            persuade_corpus   \n",
       "4                         Phones and driving            persuade_corpus   \n",
       "...                                      ...                        ...   \n",
       "73567  Grades for extracurricular activities  persuade_finetuned_llamas   \n",
       "73568  Grades for extracurricular activities  persuade_finetuned_llamas   \n",
       "73569  Grades for extracurricular activities  persuade_finetuned_llamas   \n",
       "73570  Grades for extracurricular activities  persuade_finetuned_llamas   \n",
       "73571  Grades for extracurricular activities  persuade_finetuned_llamas   \n",
       "\n",
       "       RDizzl3_seven  model  \\\n",
       "0              False  human   \n",
       "1              False  human   \n",
       "2              False  human   \n",
       "3              False  human   \n",
       "4              False  human   \n",
       "...              ...    ...   \n",
       "73567          False  llama   \n",
       "73568          False  llama   \n",
       "73569          False  llama   \n",
       "73570          False  llama   \n",
       "73571          False  llama   \n",
       "\n",
       "                                            cleaned_text  char_count  \\\n",
       "0      phones modern humans today are always on their...        1972   \n",
       "1      this essay will explain if drivers should or s...        2018   \n",
       "2      driving while the use of cellular devices toda...        1024   \n",
       "3      phones driving drivers should not be able to u...        1183   \n",
       "4      cell phone operation while driving the ability...        1872   \n",
       "...                                                  ...         ...   \n",
       "73567  im in middle school and i think that the princ...         411   \n",
       "73568  i am writing you today to disagree with your t...        1634   \n",
       "73569  dear principal in conclusion i would observe t...        2569   \n",
       "73570  dear mrs principal in these kinds of considera...        2357   \n",
       "73571  i enjoyed form five and excitedly ex claims ed...         843   \n",
       "\n",
       "       word_count  word_density  ...  flesch_kincaid_score  flesch_score  \\\n",
       "0             378      0.191684  ...                 147.2       -286.82   \n",
       "1             366      0.181368  ...                 143.7       -283.10   \n",
       "2             178      0.173828  ...                  71.5       -100.74   \n",
       "3             207      0.174979  ...                  82.8       -130.18   \n",
       "4             332      0.177350  ...                 131.6       -257.05   \n",
       "...           ...           ...  ...                   ...           ...   \n",
       "73567          73      0.177616  ...                  29.4         14.30   \n",
       "73568         213      0.130355  ...                  89.9       -170.11   \n",
       "73569         381      0.148307  ...                 153.1       -323.71   \n",
       "73570         346      0.146797  ...                 139.4       -288.18   \n",
       "73571         134      0.158956  ...                  55.6        -64.54   \n",
       "\n",
       "       gunning_fog_score  coleman_liau_score  dale_chall_score  ari_score  \\\n",
       "0                 151.94                8.68             24.77      187.4   \n",
       "1                 148.70               10.42             24.34      182.9   \n",
       "2                  73.45               11.51             15.39       90.0   \n",
       "3                  85.70               11.58             16.57      104.3   \n",
       "4                 136.66               11.11             23.72      166.4   \n",
       "...                  ...                 ...               ...        ...   \n",
       "73567              31.39               10.82             12.88       36.9   \n",
       "73568              95.15               22.94             24.58      116.5   \n",
       "73569             157.96               17.55             31.78      196.2   \n",
       "73570             144.64               17.96             29.93      179.0   \n",
       "73571              58.08               14.64             17.47       70.5   \n",
       "\n",
       "       linsear_write_score  spache_score  ner_count  error_length  \n",
       "0                     53.0         54.82          5            55  \n",
       "1                     57.0         53.46          0            55  \n",
       "2                     61.0         27.14          0            16  \n",
       "3                     64.0         31.06          4            21  \n",
       "4                     60.0         49.31          3            29  \n",
       "...                    ...           ...        ...           ...  \n",
       "73567                 40.5         13.02          3            21  \n",
       "73568                 72.0         34.79          9           105  \n",
       "73569                 59.0         57.79         14           101  \n",
       "73570                 67.0         52.78         21           142  \n",
       "73571                 62.0         21.98          4            37  \n",
       "\n",
       "[73572 rows x 48 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('feature_text_error.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = df['cleaned_text'].tolist()\n",
    "\n",
    "count_vectorizer = CountVectorizer(max_features=5000)\n",
    "\n",
    "count_matrix = count_vectorizer.fit_transform(count_vect)\n",
    "\n",
    "count_df = pd.DataFrame(count_matrix.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
    "\n",
    "df = pd.concat([df, count_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(count_vectorizer, 'tools/count_vectorizer_50k.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram Vectorizer\n",
    "\n",
    "bigram_vect = df['cleaned_text'].tolist()\n",
    "\n",
    "bigram_vectorizer = TfidfVectorizer(ngram_range=(2, 2), max_features=5000)\n",
    "\n",
    "bigram_matrix = bigram_vectorizer.fit_transform(bigram_vect)\n",
    "\n",
    "bigram_df = pd.DataFrame(bigram_matrix.toarray(), columns=bigram_vectorizer.get_feature_names_out())\n",
    "\n",
    "df = pd.concat([df, bigram_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(bigram_vectorizer, 'tools/bigram_vectorizer_50k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigram Vectorizer\n",
    "\n",
    "trigram_vect = df['cleaned_text'].tolist()\n",
    "\n",
    "trigram_vectorizer = TfidfVectorizer(ngram_range=(3, 3), max_features=5000)\n",
    "\n",
    "trigram_matrix = trigram_vectorizer.fit_transform(trigram_vect)\n",
    "\n",
    "trigram_df = pd.DataFrame(trigram_matrix.toarray(), columns=trigram_vectorizer.get_feature_names_out())\n",
    "\n",
    "df = pd.concat([df, trigram_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(trigram_vectorizer, 'tools/trigram_vectorizer_50k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi-Trigram Vectorizer\n",
    "\n",
    "bitri_vect = df['cleaned_text'].str.strip().tolist()\n",
    "\n",
    "bitri_vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 3), max_features=5000)\n",
    "\n",
    "bichar_matrix = bitri_vectorizer.fit_transform(bitri_vect)\n",
    "\n",
    "bichar_df = pd.DataFrame(bichar_matrix.toarray(), columns=bitri_vectorizer.get_feature_names_out())\n",
    "\n",
    "bichar_df.columns = bichar_df.columns.str.strip()\n",
    "\n",
    "bichar_df = bichar_df.loc[:, ~bichar_df.columns.duplicated()]\n",
    "\n",
    "df = pd.concat([df, bichar_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(bitri_vectorizer, 'tools/bitri_vectorizer_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical Diversity\n",
    "\n",
    "ttr_list = [len(set(word_tokenize(text.lower()))) / len(word_tokenize(text.lower())) for text in df['cleaned_text']]\n",
    "\n",
    "ttr_df = pd.DataFrame({'lexical_diversity': ttr_list})\n",
    "\n",
    "df['lexical_diversity'] = ttr_df['lexical_diversity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('DATA_SET/final_test_v2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
